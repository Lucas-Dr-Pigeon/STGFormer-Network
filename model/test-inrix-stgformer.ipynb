{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb73d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import yaml\n",
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9c1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dachuan/anaconda3/envs/deep/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"..\")\n",
    "from lib.utils import (\n",
    "    MaskedMAELoss,\n",
    "    MaskedHuberLoss,\n",
    "    print_log,\n",
    "    seed_everything,\n",
    "    set_cpu_num,\n",
    "    masked_mae_loss,\n",
    "    CustomJSONEncoder,\n",
    ")\n",
    "from lib.metrics import RMSE_MAE_MAPE\n",
    "from lib.data_prepare import get_dataloaders_from_index_data, load_inrix_data_with_details\n",
    "from model.STGformer import STGformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4408c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"INRIX_Manhattan\"\n",
    "MODE = 'test'\n",
    "DEVICE = 'cuda:1'\n",
    "SHIFT = True\n",
    "SCALER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b251b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference_graph(model):\n",
    "    graph = torch.matmul(model.adaptive_embedding, model.adaptive_embedding.transpose(1, 2))\n",
    "    graph = model.pooling(graph.transpose(0, 2)).transpose(0, 2)\n",
    "    graph = nn.functional.relu(graph)\n",
    "    graph = nn.functional.softmax(graph, dim=-1)\n",
    "    return graph\n",
    "\n",
    "def eval_model(model, valset_loader, criterion):\n",
    "    model.eval()\n",
    "    batch_loss_list = []\n",
    "    for x_batch, y_batch in valset_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "        out_batch = model(x_batch)\n",
    "        out_batch = SCALER.inverse_transform(out_batch)\n",
    "        loss = criterion(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "    return np.mean(batch_loss_list)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    y = []\n",
    "    out = []\n",
    "\n",
    "    for x_batch, y_batch in tqdm(loader):\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "        out_batch = model(x_batch)\n",
    "        out_batch = SCALER.inverse_transform(out_batch)\n",
    "\n",
    "        out_batch = out_batch.cpu().numpy()\n",
    "        y_batch = y_batch.cpu().numpy()\n",
    "        out.append(out_batch)\n",
    "        y.append(y_batch)\n",
    "    _, _, num_nodes, _ = out_batch.shape\n",
    "    out = np.vstack(out).reshape(-1, 1, num_nodes)  # (samples, out_steps, num_nodes)\n",
    "    y = np.vstack(y).reshape(-1, 1, num_nodes)\n",
    "\n",
    "    return y, out\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(model, testset_loader, log=None):\n",
    "    model.eval()\n",
    "    print_log(\"--------- Test ---------\", log=log)\n",
    "\n",
    "    start = time.time()\n",
    "    y_true, y_pred = predict(model, testset_loader)\n",
    "    end = time.time()\n",
    "\n",
    "    rmse_all, mae_all, mape_all = RMSE_MAE_MAPE(y_true, y_pred)\n",
    "    out_str = \"All Steps RMSE = %.5f, MAE = %.5f, MAPE = %.5f\\n\" % (\n",
    "        rmse_all,\n",
    "        mae_all,\n",
    "        mape_all,\n",
    "    )\n",
    "    # print (f\"--- y_true: {y_true.shape}  y_pred: {y_pred.shape} ---\")\n",
    "    out_steps = y_pred.shape[1]\n",
    "    for i in range(out_steps):\n",
    "        rmse, mae, mape = RMSE_MAE_MAPE(y_true[:, i, :], y_pred[:, i, :])\n",
    "        out_str += \"Step %d RMSE = %.5f, MAE = %.5f, MAPE = %.5f\\n\" % (\n",
    "            i + 1,\n",
    "            rmse,\n",
    "            mae,\n",
    "            mape,\n",
    "        )\n",
    "\n",
    "    print_log(out_str, log=log, end=\"\")\n",
    "    print_log(\"Inference time: %.2f s\" % (end - start), log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b75c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "from scipy.spatial import cKDTree  # if you don't have SciPy, see fallback note below\n",
    "\n",
    "def _line_endpoints(line):\n",
    "    \"\"\"Return a list of endpoints [(x1,y1),(x2,y2)] for a LineString/MultiLineString.\"\"\"\n",
    "    if line.is_empty:\n",
    "        return []\n",
    "    if isinstance(line, LineString):\n",
    "        coords = list(line.coords)\n",
    "        if len(coords) < 2:\n",
    "            return []\n",
    "        return [coords[0], coords[-1]]\n",
    "    elif isinstance(line, MultiLineString):\n",
    "        # take endpoints of each part (dedupe later)\n",
    "        pts = []\n",
    "        for part in line.geoms:\n",
    "            if part.length > 0:\n",
    "                c = list(part.coords)\n",
    "                pts.extend([c[0], c[-1]])\n",
    "        # deduplicate very-close endpoints inside a multilinestring\n",
    "        if not pts:\n",
    "            return []\n",
    "        pts = np.array(pts)\n",
    "        # simple dedupe with rounding to 1e-6 map units (safe after projecting to meters)\n",
    "        uniq, idx = np.unique(np.round(pts, 6), axis=0, return_index=True)\n",
    "        pts = pts[np.sort(idx)]\n",
    "        return [tuple(p) for p in pts[:2]] if len(pts) >= 2 else [tuple(pts[0])]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def endpoint_adjacency(\n",
    "    roads_gdf: gpd.GeoDataFrame,\n",
    "    d: float = 20.0,\n",
    "    crs_metric: str | None = None,\n",
    "    id_col: str | None = None,\n",
    "    return_sparse: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an NxN binary adjacency where entry[i,j]=1 if any endpoint of link i\n",
    "    is within distance d (meters) of any endpoint of link j.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    roads_gdf : GeoDataFrame of LineString/MultiLineString\n",
    "    d         : float, distance threshold in meters\n",
    "    crs_metric: str or EPSG code. If provided (recommended), reprojects to this metric CRS.\n",
    "                If None, assumes the GeoDataFrame is already in a metric CRS.\n",
    "    id_col    : optional column with stable link IDs. If None, uses row order [0..N-1].\n",
    "    return_sparse : if True, returns a scipy.sparse.csr_matrix; else returns a dense np.uint8 array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : (N,N) adjacency (csr_matrix or np.ndarray)\n",
    "    index_to_id : list mapping row index -> link id (if id_col given, otherwise same as index)\n",
    "    \"\"\"\n",
    "    # 1) project to meters if requested\n",
    "    g = roads_gdf.copy()\n",
    "    if crs_metric is not None:\n",
    "        g = g.to_crs(crs_metric)\n",
    "\n",
    "    # 2) establish link index <-> id\n",
    "    if id_col is not None and id_col in g.columns:\n",
    "        link_ids = list(g[id_col].values)\n",
    "    else:\n",
    "        link_ids = list(range(len(g)))\n",
    "    N = len(link_ids)\n",
    "\n",
    "    # 3) collect endpoints (2 per link, but may be fewer if geometry invalid/degenerate)\n",
    "    ep_coords = []          # shape (~2N, 2)\n",
    "    ep_link_idx = []        # which link this endpoint belongs to\n",
    "    for i, geom in enumerate(g.geometry.values):\n",
    "        if geom is None or geom.is_empty:\n",
    "            continue\n",
    "        pts = _line_endpoints(geom)\n",
    "        # keep at most 2 endpoints per link; if only one found (degenerate), keep it\n",
    "        for p in pts[:2]:\n",
    "            ep_coords.append(p)\n",
    "            ep_link_idx.append(i)\n",
    "\n",
    "    if len(ep_coords) == 0:\n",
    "        # no endpoints -> empty adjacency\n",
    "        if return_sparse:\n",
    "            from scipy.sparse import csr_matrix\n",
    "            return csr_matrix((N, N), dtype=np.uint8), link_ids\n",
    "        else:\n",
    "            return np.zeros((N, N), dtype=np.uint8), link_ids\n",
    "\n",
    "    ep_coords = np.asarray(ep_coords, dtype=float)\n",
    "    ep_link_idx = np.asarray(ep_link_idx, dtype=int)\n",
    "\n",
    "    # 4) radius search over endpoints\n",
    "    tree = cKDTree(ep_coords)\n",
    "    # For each endpoint index u, find all endpoint indices v within d\n",
    "    # query_ball_point returns variable-length lists per u\n",
    "    nbrs = tree.query_ball_point(ep_coords, r=d)\n",
    "\n",
    "    # 5) fill adjacency using (link_u, link_v) from endpoint pairs\n",
    "    if return_sparse:\n",
    "        from scipy.sparse import coo_matrix\n",
    "        rows, cols = [], []\n",
    "        for u, vs in enumerate(nbrs):\n",
    "            lu = ep_link_idx[u]\n",
    "            for v in vs:\n",
    "                lv = ep_link_idx[v]\n",
    "                if lu == lv:\n",
    "                    continue  # skip self\n",
    "                rows.append(lu)\n",
    "                cols.append(lv)\n",
    "        if rows:\n",
    "            data = np.ones(len(rows), dtype=np.uint8)\n",
    "            A = coo_matrix((data, (rows, cols)), shape=(N, N), dtype=np.uint8).tocsr()\n",
    "            # make symmetric (undirected) and zero diagonal\n",
    "            A = ((A + A.T) > 0).astype(np.uint8)\n",
    "            A.setdiag(0)\n",
    "            A.eliminate_zeros()\n",
    "        else:\n",
    "            from scipy.sparse import csr_matrix\n",
    "            A = csr_matrix((N, N), dtype=np.uint8)\n",
    "        return A, link_ids\n",
    "    else:\n",
    "        A = np.zeros((N, N), dtype=np.uint8)\n",
    "        for u, vs in enumerate(nbrs):\n",
    "            lu = ep_link_idx[u]\n",
    "            for v in vs:\n",
    "                lv = ep_link_idx[v]\n",
    "                if lu == lv:\n",
    "                    continue\n",
    "                A[lu, lv] = 1\n",
    "                A[lv, lu] = 1\n",
    "        np.fill_diagonal(A, 0)\n",
    "        return A, link_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12278436",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randint(0,1000)  # set random seed here\n",
    "seed_everything(seed)\n",
    "set_cpu_num(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8193b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_Weight = '../saved_models/STGformer-INRIX_MANHATTAN-2025-09-29-09-19-43.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d61b3da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INRIX_MANHATTAN\n",
      "--- Building Sequences ---\n",
      "--- Scaling Sequences ---\n",
      "Trainset:\tx-(63057, 1212, 12, 1)\ty-(63057, 1212, 1, 1)\n",
      "Valset:  \tx-(21019, 1212, 12, 1)  \ty-(21019, 1212, 1, 1)\n",
      "Testset:\tx-(21020, 1212, 12, 1)\ty-(21020, 1212, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = DATASET.upper()\n",
    "data_path = f\"../data/{dataset}\"\n",
    "\n",
    "model_name = STGformer.__name__\n",
    "\n",
    "with open(f\"{model_name}.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "cfg = cfg[dataset]\n",
    "\n",
    "# ------------------------------- make log file ------------------------------ #\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "log_path = f\"../logs/\"\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "log = os.path.join(log_path, f\"{model_name}-{dataset}-{now}.log\")\n",
    "log = open(log, \"a\", encoding=\"utf-8\")\n",
    "log.seek(0)\n",
    "log.truncate()\n",
    "\n",
    "# ------------------------------- load dataset ------------------------------- #\n",
    "\n",
    "print_log(dataset, log=log)\n",
    "    \n",
    "(trainset_loader, valset_loader, testset_loader, SCALER, adj_mx, gdf, tmc) = (\n",
    "    load_inrix_data_with_details(\n",
    "        \"/home/dachuan/Productivities/Spectral GAT/NY/adj_manhattan.npy\",\n",
    "        \"/home/dachuan/Productivities/Spectral GAT/SPGAT/Data/speed_19_Manhattan_5min_py36\",\n",
    "        \"/home/dachuan/Productivities/Spectral GAT/NY/Manhattan_FinalVersion.shp\",\n",
    "        \"/home/dachuan/Productivities/Spectral GAT/NY/TMC_FinalVersion.csv\",\n",
    "        tod=cfg.get(\"time_of_day\"),\n",
    "        dow=cfg.get(\"day_of_week\"),\n",
    "        batch_size=cfg.get(\"batch_size\", 64),\n",
    "        history_seq_len=cfg.get(\"in_steps\"),\n",
    "        future_seq_len=cfg.get(\"out_steps\"),\n",
    "        log=log,\n",
    "        train_ratio=cfg.get(\"train_size\", 0.6),\n",
    "        valid_ratio=cfg.get(\"val_size\", 0.2),\n",
    "        shift=SHIFT,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print_log(log=log)\n",
    "supports = [torch.tensor(i).to(DEVICE) for i in adj_mx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ecdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Iterable, Sequence, Tuple, Optional\n",
    "\n",
    "# -------------------- helpers --------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def _compute_train_node_stats_from_loader(\n",
    "    trainset_loader: Iterable[Tuple[torch.Tensor, torch.Tensor]],\n",
    "    scaler,\n",
    "    device: torch.device | str = \"cpu\",\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    total_sum = None\n",
    "    total_sumsq = None\n",
    "    total_count = 0\n",
    "\n",
    "    for batch_x, batch_y in trainset_loader:\n",
    "        bx = batch_x.to(device)                # (B, T_h, N, C)\n",
    "        by = batch_y.to(device)                # (B, T_f, N, C)\n",
    "        bx_raw = scaler.inverse_transform(bx)  # (B, T_h, N, C)\n",
    "        raw = torch.cat([bx_raw, by], dim=1).squeeze(-1)  # (B, T, N)\n",
    "\n",
    "        B, T, N = raw.shape\n",
    "        flat = raw.reshape(B*T, N)\n",
    "        s  = flat.sum(dim=0)\n",
    "        ss = (flat * flat).sum(dim=0)\n",
    "\n",
    "        if total_sum is None:\n",
    "            total_sum, total_sumsq = s.clone(), ss.clone()\n",
    "        else:\n",
    "            total_sum  += s\n",
    "            total_sumsq += ss\n",
    "        total_count += B*T\n",
    "\n",
    "    mu  = total_sum / max(total_count, 1)\n",
    "    var = (total_sumsq / max(total_count, 1)) - mu*mu\n",
    "    var = torch.clamp(var, min=0.0)\n",
    "    std = torch.sqrt(var + 1e-8)\n",
    "    return mu.float(), std.float()\n",
    "\n",
    "\n",
    "def _rectified_channels_from_dv(x_z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    dv = torch.diff(x_z, dim=1, prepend=x_z[:, :1, :])  # (B,T,N)\n",
    "    r = torch.relu(-dv)   # reductions (down moves)\n",
    "    u = torch.relu( dv)   # increases (up moves)\n",
    "    return r, u\n",
    "\n",
    "\n",
    "def _xcorr_positive_lags_allpairs(\n",
    "    chan: torch.Tensor,\n",
    "    lags: Sequence[int],\n",
    "    eps: float = 1e-8\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    chan: (B,T,N) one rectified channel\n",
    "    Returns rho: (B,L,N,N) where for lag ℓ we correlate chan[:, :T-ℓ, i] with chan[:, ℓ:, j]\n",
    "    \"\"\"\n",
    "    B, T, N = chan.shape\n",
    "    L = len(lags)\n",
    "    out = chan.new_zeros((B, L, N, N))\n",
    "\n",
    "    for li, LAG in enumerate(lags):\n",
    "        if LAG <= 0 or LAG >= T:\n",
    "            continue\n",
    "        A  = chan[:, :T-LAG, :]     # (B,Tl,N)\n",
    "        B_ = chan[:,  LAG:,  :]     # (B,Tl,N)\n",
    "        Tl = A.shape[1]\n",
    "\n",
    "        A_c = A - A.mean(dim=1, keepdim=True)\n",
    "        B_c = B_ - B_.mean(dim=1, keepdim=True)\n",
    "\n",
    "        A_std = torch.sqrt(A_c.pow(2).mean(dim=1) + eps)   # (B,N)\n",
    "        B_std = torch.sqrt(B_c.pow(2).mean(dim=1) + eps)   # (B,N)\n",
    "\n",
    "        cov = torch.matmul(A_c.transpose(1, 2), B_c) / max(Tl - 1, 1)  # (B,N,N)\n",
    "        denom = (A_std.unsqueeze(-1) * B_std.unsqueeze(1)).clamp_min(eps)\n",
    "        out[:, li] = cov / denom\n",
    "    return out\n",
    "\n",
    "\n",
    "def _maybe_to_sparse(x: torch.Tensor, sparse: bool) -> torch.Tensor:\n",
    "    if not sparse:\n",
    "        return x\n",
    "    # Ensure float dtype for masks, too (0/1)\n",
    "    if x.dtype != torch.float32 and x.dtype != torch.float64:\n",
    "        x = x.float()\n",
    "    return x.to_sparse()\n",
    "\n",
    "\n",
    "# -------------------- main API --------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_batchwise_ccf_two_channels_from_loader(\n",
    "    trainset_loader: Iterable[Tuple[torch.Tensor, torch.Tensor]],\n",
    "    lags: Sequence[int],\n",
    "    scaler,\n",
    "    device: torch.device | str = \"cpu\",\n",
    "    A_mask: Optional[torch.Tensor] = None,             # (N,N) 1=physically connected\n",
    "    phys_thresholds: Tuple[float, float] = (0.2, 0.5), # (τ_lo, τ_hi)\n",
    "    sparse: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Yields per batch a 6-tuple:\n",
    "      (rho_red,  sig_red,  band_red,\n",
    "       rho_up,   sig_up,   band_up)\n",
    "\n",
    "    Shapes (dense):\n",
    "      each is (B, L, N, N)\n",
    "\n",
    "    - A_mask (N,N): if provided, masks all three outputs per channel (elementwise multiply).\n",
    "      You control self-loops by A_mask diagonal (1 allow / 0 forbid).\n",
    "    - phys_thresholds = (τ_lo, τ_hi):\n",
    "        * significance mask: (ρ > τ_hi)  → 1 else 0\n",
    "        * band_mask: 0 if τ_lo < ρ < τ_hi (mid-band), else 1\n",
    "    - sparse=True returns all tensors as sparse COO.\n",
    "    \"\"\"\n",
    "    assert len(lags) > 0, \"Provide at least one positive lag.\"\n",
    "    tau_lo, tau_hi = phys_thresholds\n",
    "    assert tau_lo < tau_hi, \"Require tau_lo < tau_hi.\"\n",
    "\n",
    "    # compute per-node stats on raw speeds\n",
    "    mu, std = _compute_train_node_stats_from_loader(trainset_loader, scaler, device)\n",
    "\n",
    "    # Prepare broadcastable A_mask if given\n",
    "    if A_mask is not None:\n",
    "        A_mask = A_mask.to(device=device).bool()  # (N,N)\n",
    "        # For broadcasting over (B,L,N,N):\n",
    "        def _apply_phys_mask(x: torch.Tensor) -> torch.Tensor:\n",
    "            return x * A_mask.view(1, 1, *A_mask.shape)\n",
    "    else:\n",
    "        def _apply_phys_mask(x: torch.Tensor) -> torch.Tensor:\n",
    "            return x\n",
    "\n",
    "    # Second pass: compute per-batch outputs\n",
    "    for batch_x, batch_y in trainset_loader:\n",
    "        bx = batch_x.to(device)                # (B, T_h, N, C)\n",
    "        by = batch_y.to(device)                # (B, T_f, N, C)\n",
    "        bx_raw = scaler.inverse_transform(bx)  # -> raw speeds\n",
    "        raw = torch.cat([bx_raw, by], dim=1).squeeze(-1)  # (B, T, N)\n",
    "\n",
    "        B, T, N = raw.shape\n",
    "        x_z = (raw - mu.view(1, 1, N)) / std.view(1, 1, N)  # z-score per node\n",
    "        r, u = _rectified_channels_from_dv(x_z)             # (B,T,N) each\n",
    "\n",
    "        # Correlations per lag\n",
    "        rho_red = _xcorr_positive_lags_allpairs(r, lags)    # (B,L,N,N)\n",
    "        rho_up  = _xcorr_positive_lags_allpairs(u, lags)\n",
    "\n",
    "        # Apply physical mask to correlations\n",
    "        rho_red = _apply_phys_mask(rho_red)\n",
    "        rho_up  = _apply_phys_mask(rho_up)\n",
    "\n",
    "        # Threshold-based masks\n",
    "        # significance: 1 where rho > τ_hi\n",
    "        sig_red  = (rho_red > tau_hi).float()\n",
    "        sig_up   = (rho_up  > tau_hi).float()\n",
    "\n",
    "        # band_mask: 0 if τ_lo < rho < τ_hi, else 1\n",
    "        mid_red  = ((rho_red > tau_lo) & (rho_red < tau_hi)).float()\n",
    "        band_red = (1.0 - mid_red)  # zero in mid-band, one otherwise\n",
    "\n",
    "        mid_up   = ((rho_up  > tau_lo) & (rho_up  < tau_hi)).float()\n",
    "        band_up  = (1.0 - mid_up)\n",
    "\n",
    "        # Apply physical mask to masks as well (to zero any forbidden pairs)\n",
    "        sig_red  = _apply_phys_mask(sig_red)\n",
    "        band_red = _apply_phys_mask(band_red)\n",
    "        sig_up   = _apply_phys_mask(sig_up)\n",
    "        band_up  = _apply_phys_mask(band_up)\n",
    "\n",
    "        # Convert to sparse (optional)\n",
    "        rho_red  = _maybe_to_sparse(rho_red,  sparse)\n",
    "        sig_red  = _maybe_to_sparse(sig_red,  sparse)\n",
    "        band_red = _maybe_to_sparse(band_red, sparse)\n",
    "\n",
    "        rho_up   = _maybe_to_sparse(rho_up,   sparse)\n",
    "        sig_up   = _maybe_to_sparse(sig_up,   sparse)\n",
    "        band_up  = _maybe_to_sparse(band_up,  sparse)\n",
    "\n",
    "        yield (sig_red, band_red,\n",
    "               sig_up,  band_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab49e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Iterable, Sequence, Tuple, Optional\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_ccf_two_channels_edges(\n",
    "    trainset_loader: Iterable[Tuple[torch.Tensor, torch.Tensor]],\n",
    "    lags: Sequence[int],\n",
    "    scaler,\n",
    "    A_mask: torch.Tensor,                 # (N,N) bool, REQUIRED so we can avoid N^2\n",
    "    phys_thresholds: Tuple[float, float] = (0.2, 0.5),\n",
    "    device: str = \"cpu\",          # do heavy math on CPU by default\n",
    "):\n",
    "    \"\"\"\n",
    "    Yields per batch:\n",
    "      dict with:\n",
    "        'rho_red_edge' : (B,L,E)\n",
    "        'rho_up_edge'  : (B,L,E)\n",
    "        'sig_red_edge' : (B,L,E)  (1 if rho>hi)\n",
    "        'sig_up_edge'  : (B,L,E)\n",
    "        'band_red_edge': (B,L,E)  (0 if lo<rho<hi else 1)\n",
    "        'band_up_edge' : (B,L,E)\n",
    "        plus (optional) sparse 4D coo: 'rho_red_coo', 'rho_up_coo', 'sig_red_coo', ...\n",
    "\n",
    "    Notes:\n",
    "      - Only edges where A_mask[i,j]==1 are computed (E = nnz).\n",
    "      - No dense (B,L,N,N) tensors are materialized.\n",
    "    \"\"\"\n",
    "    assert A_mask.dtype == torch.bool\n",
    "    A_mask = A_mask.to(device)\n",
    "    N = A_mask.shape[0]\n",
    "    I, J = A_mask.nonzero(as_tuple=True)   # (E,)\n",
    "    E = I.numel()\n",
    "    tau_lo, tau_hi = phys_thresholds\n",
    "    assert tau_lo < tau_hi\n",
    "\n",
    "    # 1) per-node stats on CPU (raw)\n",
    "    def pass_stats():\n",
    "        total_sum = torch.zeros(N)\n",
    "        total_sumsq = torch.zeros(N)\n",
    "        total_cnt = 0\n",
    "        for bx, by in trainset_loader:\n",
    "            bx_raw = scaler.inverse_transform(bx).squeeze(-1)   # (B,Th,N)\n",
    "            raw = torch.cat([bx_raw, by.squeeze(-1)], dim=1)    # (B,T,N)\n",
    "            B, T, _ = raw.shape\n",
    "            flat = raw.reshape(B*T, N)                          # CPU\n",
    "            total_sum  += flat.sum(0)\n",
    "            total_sumsq += (flat*flat).sum(0)\n",
    "            total_cnt   += B*T\n",
    "        mu = total_sum / max(total_cnt,1)\n",
    "        var = (total_sumsq / max(total_cnt,1)) - mu*mu\n",
    "        std = torch.sqrt(var.clamp_min(0) + 1e-8)\n",
    "        return mu, std\n",
    "\n",
    "    mu, std = pass_stats()\n",
    "    mu = mu.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "    # 2) second pass: compute edgewise correlations\n",
    "    for bx, by in tqdm(trainset_loader):\n",
    "        # keep on CPU to save VRAM\n",
    "        bx_raw = scaler.inverse_transform(bx).squeeze(-1)   # (B,Th,N)\n",
    "        raw = torch.cat([bx_raw, by.squeeze(-1)], dim=1).to(device)    # (B,T,N)\n",
    "        B, T, _ = raw.shape\n",
    "\n",
    "        x_z = (raw - mu.view(1,1,N)) / std.view(1,1,N)      # (B,T,N)\n",
    "        # rectified channels from Δv\n",
    "        dv = torch.diff(x_z, dim=1, prepend=x_z[:, :1, :])  # (B,T,N)\n",
    "        r = torch.relu(-dv)\n",
    "        u = torch.relu( dv)\n",
    "\n",
    "        L = len(lags)\n",
    "        # allocate edgewise outputs on CPU\n",
    "        rho_red_edge  = torch.zeros(B, L, E)\n",
    "        rho_up_edge   = torch.zeros(B, L, E)\n",
    "        sig_red_edge  = torch.zeros(B, L, E)\n",
    "        sig_up_edge   = torch.zeros(B, L, E)\n",
    "        band_red_edge = torch.ones (B, L, E)   # default 1; set to 0 in mid band\n",
    "        band_up_edge  = torch.ones (B, L, E)\n",
    "\n",
    "        for li, lag in enumerate(lags):\n",
    "            if lag <= 0 or lag >= T: \n",
    "                continue\n",
    "            A_t  = r[:, :T-lag, :] ; B_t  = r[:, lag:, :]   # (B,Tl,N)\n",
    "            A_t2 = u[:, :T-lag, :] ; B_t2 = u[:, lag:, :]   # for increases\n",
    "            Tl = A_t.shape[1]\n",
    "\n",
    "            # center over time\n",
    "            A_c  = A_t  - A_t .mean(1, keepdim=True)\n",
    "            B_c  = B_t  - B_t .mean(1, keepdim=True)\n",
    "            A2_c = A_t2 - A_t2.mean(1, keepdim=True)\n",
    "            B2_c = B_t2 - B_t2.mean(1, keepdim=True)\n",
    "\n",
    "            # per-node std (B,N)\n",
    "            stdA  = torch.sqrt((A_c .pow(2)).mean(1) + 1e-8)\n",
    "            stdB  = torch.sqrt((B_c .pow(2)).mean(1) + 1e-8)\n",
    "            stdA2 = torch.sqrt((A2_c.pow(2)).mean(1) + 1e-8)\n",
    "            stdB2 = torch.sqrt((B2_c.pow(2)).mean(1) + 1e-8)\n",
    "\n",
    "            # gather only needed nodes → (B,Tl,E)\n",
    "            Ai  = A_c [:, :, I] ; Bj  = B_c [:, :, J]\n",
    "            Ai2 = A2_c[:, :, I] ; Bj2 = B2_c[:, :, J]\n",
    "            # covariances → (B,E)\n",
    "            cov  = (Ai  * Bj ).sum(1) / max(Tl-1, 1)\n",
    "            cov2 = (Ai2 * Bj2).sum(1) / max(Tl-1, 1)\n",
    "            # std pairs → (B,E)\n",
    "            s_ij  = (stdA .gather(1, I.unsqueeze(0).expand(B,-1)) *\n",
    "                     stdB .gather(1, J.unsqueeze(0).expand(B,-1))).clamp_min(1e-8)\n",
    "            s_ij2 = (stdA2.gather(1, I.unsqueeze(0).expand(B,-1)) *\n",
    "                     stdB2.gather(1, J.unsqueeze(0).expand(B,-1))).clamp_min(1e-8)\n",
    "\n",
    "            rho   = cov  / s_ij\n",
    "            rho2  = cov2 / s_ij2\n",
    "\n",
    "            rho_red_edge[:, li] = rho\n",
    "            rho_up_edge [:, li] = rho2\n",
    "\n",
    "            # thresholds\n",
    "            sig_red_edge[:, li]  = (rho  > tau_hi).float()\n",
    "            sig_up_edge [:, li]  = (rho2 > tau_hi).float()\n",
    "            mid_red  = (rho  > tau_lo) & (rho  < tau_hi)\n",
    "            mid_up   = (rho2 > tau_lo) & (rho2 < tau_hi)\n",
    "            band_red_edge[:, li][mid_red] = 0.0\n",
    "            band_up_edge [:, li][mid_up ] = 0.0\n",
    "\n",
    "        out = {\n",
    "            \"rho_red_edge\":  rho_red_edge,\n",
    "            \"rho_up_edge\":   rho_up_edge,\n",
    "            \"sig_red_edge\":  sig_red_edge,\n",
    "            \"sig_up_edge\":   sig_up_edge,\n",
    "            \"band_red_edge\": band_red_edge,\n",
    "            \"band_up_edge\":  band_up_edge,\n",
    "            \"edge_index\":    torch.stack([I, J], dim=0)  # (2,E)\n",
    "        }\n",
    "\n",
    "        yield out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b652b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_adj = endpoint_adjacency(gdf, 20.0, 'EPSG: 32618')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c97ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Sequence, Tuple\n",
    "\n",
    "@torch.no_grad()\n",
    "def corr_labels_from_batch(\n",
    "    batch_x: torch.Tensor,               # (B, T_h, N, C) normalized\n",
    "    batch_y: torch.Tensor,               # (B, T_f, N, C) raw\n",
    "    scaler,                              # has .inverse_transform(tensor) -> raw\n",
    "    A_mask: torch.Tensor,                # (N, N) bool; 1 = physically allowed (i->j)\n",
    "    lags: Sequence[int],                 # e.g., [1,2,3]\n",
    "    phys_thresholds: Tuple[float, float] = (0.2, 0.5),\n",
    "    label_only: bool = False,\n",
    "    device: str = \"cuda:0\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns (edge-wise, NOT N^2):\n",
    "      if label_only=False:\n",
    "          rho_red_edge : (B, L, E) float32\n",
    "          rho_up_edge  : (B, L, E) float32\n",
    "          edge_index   : (2, E) long\n",
    "      else:\n",
    "          sig_red_edge : (B, L, E) bool\n",
    "          sig_up_edge  : (B, L, E) bool\n",
    "          edge_index   : (2, E) long\n",
    "    \"\"\"\n",
    "    assert A_mask.dtype == torch.bool, \"A_mask must be boolean (N,N)\"\n",
    "    tau_lo, tau_hi = phys_thresholds\n",
    "    L = len(lags)\n",
    "    assert L > 0\n",
    "\n",
    "    # ---- move mask + edge list to device ----\n",
    "    A_mask = A_mask.to(device)\n",
    "    I, J = A_mask.nonzero(as_tuple=True)          # (E,)\n",
    "    edge_index = torch.stack([I, J], dim=0)       # (2, E)\n",
    "    E = I.numel()\n",
    "    N = A_mask.shape[0]\n",
    "\n",
    "    # ---- unnormalize x, concat with raw y → raw speeds (B,T,N) ----\n",
    "    bx_raw = scaler.inverse_transform(batch_x.to(device)).squeeze(-1)  # (B, T_h, N)\n",
    "    by_raw = batch_y.to(device).squeeze(-1)                            # (B, T_f, N)\n",
    "    x_raw  = torch.cat([bx_raw, by_raw], dim=1)                        # (B, T, N)\n",
    "    B, T, _ = x_raw.shape\n",
    "\n",
    "    # ---- first-diff → rectified channels ----\n",
    "    dv = torch.diff(x_raw, dim=1, prepend=x_raw[:, :1, :])             # (B, T, N)\n",
    "    r  = torch.relu(-dv)                                               # reductions\n",
    "    u  = torch.relu( dv)                                               # increases\n",
    "\n",
    "    # ---- allocate outputs ----\n",
    "    if label_only:\n",
    "        sig_red_edge = torch.zeros((B, L, E), dtype=torch.bool, device=device)\n",
    "        sig_up_edge  = torch.zeros((B, L, E), dtype=torch.bool, device=device)\n",
    "    else:\n",
    "        rho_red_edge = torch.zeros((B, L, E), dtype=torch.float32, device=device)\n",
    "        rho_up_edge  = torch.zeros((B, L, E), dtype=torch.float32, device=device)\n",
    "\n",
    "    # ---- per-lag correlation ----\n",
    "    eps = 1e-8\n",
    "    for li, lag in enumerate(lags):\n",
    "        if lag <= 0 or lag >= T:\n",
    "            continue\n",
    "\n",
    "        # reductions channel\n",
    "        A  = r[:, :T-lag, :]\n",
    "        B_ = r[:,  lag:,  :]\n",
    "        Tl = A.shape[1]\n",
    "\n",
    "        A_c = A - A.mean(dim=1, keepdim=True)\n",
    "        B_c = B_ - B_.mean(dim=1, keepdim=True)\n",
    "        stdA = torch.sqrt((A_c.pow(2)).mean(dim=1) + eps)\n",
    "        stdB = torch.sqrt((B_c.pow(2)).mean(dim=1) + eps)\n",
    "\n",
    "        Ai = A_c.index_select(2, I)\n",
    "        Bj = B_c.index_select(2, J)\n",
    "        cov  = (Ai * Bj).sum(dim=1) / max(Tl - 1, 1)\n",
    "\n",
    "        s_ij = (stdA.gather(1, I.expand(B, -1)) *\n",
    "                stdB.gather(1, J.expand(B, -1))).clamp_min(eps)\n",
    "        rho  = cov / s_ij\n",
    "\n",
    "        if label_only:\n",
    "            sig_red_edge[:, li, :] = rho > tau_hi\n",
    "        else:\n",
    "            rho_red_edge[:, li, :] = rho\n",
    "\n",
    "        # increases channel\n",
    "        A2  = u[:, :T-lag, :]\n",
    "        B2_ = u[:,  lag:,  :]\n",
    "        A2_c = A2 - A2.mean(dim=1, keepdim=True)\n",
    "        B2_c = B2_ - B2_.mean(dim=1, keepdim=True)\n",
    "        stdA2 = torch.sqrt((A2_c.pow(2)).mean(dim=1) + eps)\n",
    "        stdB2 = torch.sqrt((B2_c.pow(2)).mean(dim=1) + eps)\n",
    "\n",
    "        Ai2 = A2_c.index_select(2, I)\n",
    "        Bj2 = B2_c.index_select(2, J)\n",
    "        cov2  = (Ai2 * Bj2).sum(dim=1) / max(Tl - 1, 1)\n",
    "\n",
    "        s_ij2 = (stdA2.gather(1, I.expand(B, -1)) *\n",
    "                 stdB2.gather(1, J.expand(B, -1))).clamp_min(eps)\n",
    "        rho2 = cov2 / s_ij2\n",
    "\n",
    "        if label_only:\n",
    "            sig_up_edge[:, li, :] = rho2 > tau_hi\n",
    "        else:\n",
    "            rho_up_edge[:, li, :] = rho2\n",
    "\n",
    "    if label_only:\n",
    "        return sig_red_edge, sig_up_edge, edge_index\n",
    "    else:\n",
    "        return rho_red_edge, rho_up_edge, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fe73455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Sequence\n",
    "\n",
    "@torch.no_grad()\n",
    "def corr_speed_posneg_from_batch(\n",
    "    batch_x: torch.Tensor,               # (B, T_h, N, C) normalized\n",
    "    batch_y: torch.Tensor,               # (B, T_f, N, C) raw\n",
    "    scaler,                              # has .inverse_transform(tensor) -> raw\n",
    "    A_mask: torch.Tensor,                # (N, N) bool; 1 = physically allowed (i->j)\n",
    "    lags: Sequence[int],                 # positive lags, e.g. [1,2,3]\n",
    "    tau_hi: float = 0.5,                 # significance threshold (magnitude)\n",
    "    label_only: bool = False,            # True → return boolean significance only\n",
    "    device: str = \"cuda:0\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Edge-only Pearson cross-correlation on *speeds* at positive lags, split into\n",
    "    positive and negative channels.\n",
    "\n",
    "    Direction: corr(v_i(t), v_j(t+lag))  so positive lag encodes i→j timing.\n",
    "\n",
    "    Returns (all on `device`):\n",
    "      if label_only=False:\n",
    "          rho_pos_edge : (B, L, E) float32   # max( rho, 0 )\n",
    "          rho_neg_edge : (B, L, E) float32   # max(-rho, 0 )  (anti-corr magnitude)\n",
    "          edge_index   : (2, E)   long       # rows [i_indices; j_indices]\n",
    "      else:\n",
    "          sig_pos_edge : (B, L, E) bool      # rho >  +tau_hi\n",
    "          sig_neg_edge : (B, L, E) bool      # rho <  -tau_hi\n",
    "          edge_index   : (2, E)   long\n",
    "    \"\"\"\n",
    "    assert A_mask.dtype == torch.bool, \"A_mask must be boolean (N,N)\"\n",
    "    assert len(lags) > 0 and all(l > 0 for l in lags), \"Provide positive lags only\"\n",
    "\n",
    "    # ---- move inputs/mask to device, build directed edge list ----\n",
    "    A_mask = A_mask.to(device)\n",
    "    I, J = A_mask.nonzero(as_tuple=True)          # (E,)\n",
    "    edge_index = torch.stack([I, J], dim=0)       # (2, E)\n",
    "    E = I.numel()\n",
    "    N = A_mask.shape[0]\n",
    "    L = len(lags)\n",
    "\n",
    "    # ---- recover raw speeds and stitch history+future along time ----\n",
    "    bx_raw = scaler.inverse_transform(batch_x.to(device)).squeeze(-1)  # (B, T_h, N)\n",
    "    by_raw = batch_y.to(device).squeeze(-1)                            # (B, T_f, N)\n",
    "    X = torch.cat([bx_raw, by_raw], dim=1)                             # (B, T, N)\n",
    "    B, T, _ = X.shape\n",
    "\n",
    "    # ---- allocate outputs ----\n",
    "    if label_only:\n",
    "        sig_pos = torch.zeros((B, L, E), dtype=torch.bool, device=device)\n",
    "        sig_neg = torch.zeros((B, L, E), dtype=torch.bool, device=device)\n",
    "    else:\n",
    "        rho_pos = torch.zeros((B, L, E), dtype=torch.float32, device=device)\n",
    "        rho_neg = torch.zeros((B, L, E), dtype=torch.float32, device=device)\n",
    "\n",
    "    # ---- per-lag Pearson correlation over the overlap window ----\n",
    "    eps = 1e-8\n",
    "    for li, lag in enumerate(lags):\n",
    "        if lag >= T:\n",
    "            continue\n",
    "\n",
    "        # i at t, j at t+lag\n",
    "        Xi = X[:, :T - lag, :]     # (B, Tl, N)\n",
    "        Xj = X[:,  lag:   , :]     # (B, Tl, N)\n",
    "        Tl = Xi.shape[1]\n",
    "\n",
    "        # center over time per node\n",
    "        Xi_c = Xi - Xi.mean(dim=1, keepdim=True)\n",
    "        Xj_c = Xj - Xj.mean(dim=1, keepdim=True)\n",
    "\n",
    "        # std over time per node\n",
    "        std_i = torch.sqrt((Xi_c.pow(2)).mean(dim=1) + eps)   # (B, N)\n",
    "        std_j = torch.sqrt((Xj_c.pow(2)).mean(dim=1) + eps)   # (B, N)\n",
    "\n",
    "        # gather only allowed edges → (B, Tl, E)\n",
    "        Ai = Xi_c.index_select(2, I)\n",
    "        Bj = Xj_c.index_select(2, J)\n",
    "\n",
    "        # covariance over time (B,E), denominator per edge (B,E)\n",
    "        cov   = (Ai * Bj).sum(dim=1) / max(Tl - 1, 1)\n",
    "        denom = (std_i.gather(1, I.expand(B, -1)) *\n",
    "                 std_j.gather(1, J.expand(B, -1))).clamp_min(eps)\n",
    "        rho   = cov / denom                                   # (B, E)\n",
    "\n",
    "        if label_only:\n",
    "            sig_pos[:, li, :] = (rho >  +tau_hi)\n",
    "            sig_neg[:, li, :] = (rho <  -tau_hi)\n",
    "        else:\n",
    "            # split channels as non-negative magnitudes\n",
    "            rho_pos[:, li, :] = torch.clamp(rho,  min=0.0)\n",
    "            rho_neg[:, li, :] = torch.clamp(-rho, min=0.0)\n",
    "\n",
    "    if label_only:\n",
    "        return sig_pos, sig_neg, edge_index\n",
    "    else:\n",
    "        return rho_pos, rho_neg, edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e9c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_row_softmax(G_logits: torch.Tensor,\n",
    "                       mask: torch.Tensor | None,\n",
    "                       temperature: float = 1.0,\n",
    "                       fallback_self_loop: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    G_logits: (B,N,N)\n",
    "    mask:     (1 or B,N,N) bool (1 = allowed; control self-loops via diag)\n",
    "    Returns row-stochastic probs over allowed neighbors.\n",
    "    \"\"\"\n",
    "    B, N, _ = G_logits.shape\n",
    "    if mask is None:\n",
    "        return F.softmax(G_logits / temperature, dim=-1)\n",
    "\n",
    "    m = mask.bool()\n",
    "    if m.dim() == 3 and m.size(0) == 1:\n",
    "        m = m.expand(B, -1, -1)  # (B,N,N)\n",
    "\n",
    "    if fallback_self_loop:\n",
    "        row_has = m.any(dim=-1)\n",
    "        if (~row_has).any():\n",
    "            eye = torch.eye(N, dtype=torch.bool, device=G_logits.device).unsqueeze(0)\n",
    "            m = torch.where((~row_has).unsqueeze(-1) & eye, True, m)\n",
    "\n",
    "    neg_inf = torch.finfo(G_logits.dtype).min / 4\n",
    "    x = torch.where(m, G_logits / temperature, torch.full_like(G_logits, neg_inf))\n",
    "    x = x - x.amax(dim=-1, keepdim=True)\n",
    "    exps = torch.exp(x) * m\n",
    "    denom = exps.sum(dim=-1, keepdim=True).clamp_min(1e-12)\n",
    "    return exps / denom  # (B,N,N)\n",
    "\n",
    "\n",
    "class DirectedLowRankGraphHead(nn.Module):\n",
    "    \"\"\"\n",
    "    (B,T,N,C) -> (B,N,N) via directed low-rank outer products.\n",
    "      - rank r=1 gives a rank-1 directed graph: G = a b^T\n",
    "      - larger r increases capacity: G = sum_k a_k b_k^T\n",
    "\n",
    "    Args:\n",
    "      in_dim:     node feature dim C (after temporal projection)\n",
    "      hidden:     hidden size in node scorers\n",
    "      rank_r:     low rank (>=1)\n",
    "      pooling:    'last' or 'mean' over time for node features\n",
    "      normalize:  'row_softmax' (row-stochastic) or 'sigmoid' (independent probs)\n",
    "      temperature: softmax/sigmoid temperature\n",
    "      nonneg:     if True, clamp a,b >= 0 (keeps non-negative weights)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden: int = 64, rank_r: int = 1,\n",
    "                 pooling: str = \"last\", normalize: str = \"sigmoid\",\n",
    "                 temperature: float = 1.0, nonneg: bool = True):\n",
    "        super().__init__()\n",
    "        assert pooling in (\"last\", \"mean\")\n",
    "        assert normalize in (\"row_softmax\", \"sigmoid\")\n",
    "        assert rank_r >= 1\n",
    "        self.pooling = pooling\n",
    "        self.normalize = normalize\n",
    "        self.temperature = temperature\n",
    "        self.nonneg = nonneg\n",
    "        self.rank_r = rank_r\n",
    "\n",
    "        # Separate source and destination scorers (directed)\n",
    "        self.src_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, rank_r)   # (B,N,r)\n",
    "        )\n",
    "        self.dst_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, rank_r)   # (B,N,r)\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor, mask_M: torch.Tensor | None = None):\n",
    "        \"\"\"\n",
    "        X: (B,T,N,C)\n",
    "        mask_M: (1 or B,N,N) bool; 1=allowed (diag controls self-loops)\n",
    "        Returns:\n",
    "          G: (B,N,N)\n",
    "        \"\"\"\n",
    "        B, T, N, C = X.shape\n",
    "        H = X[:, -1] if self.pooling == \"last\" else X.mean(dim=1)  # (B,N,C)\n",
    "\n",
    "        a = self.src_mlp(H)   # (B,N,r)\n",
    "        b = self.dst_mlp(H)   # (B,N,r)\n",
    "        if self.nonneg:\n",
    "            a = nn.functional.relu(a)\n",
    "            b = nn.functional.relu(b)\n",
    "\n",
    "        # Sum of rank-1 outer products over r:\n",
    "        # G_logits[b,i,j] = sum_k a[b,i,k] * b[b,j,k]\n",
    "        G_logits = torch.einsum(\"bik,bjk->bij\", a, b)  # (B,N,N)\n",
    "\n",
    "        if self.normalize == \"row_softmax\":\n",
    "            G = masked_row_softmax(G_logits, mask_M, self.temperature, fallback_self_loop=True)\n",
    "        else:\n",
    "            G = torch.sigmoid(G_logits / self.temperature)\n",
    "            if mask_M is not None:\n",
    "                G = G * mask_M\n",
    "        return G  # (B,N,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276861b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d0aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = next(iter(trainset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a61b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl = [ DirectedLowRankGraphHead(in_dim=40, hidden=64, rank_r=1,\n",
    "                 pooling=\"last\", normalize=\"sigmoid\",\n",
    "                 temperature=1.0) for _ in range(3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba284584",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_proj = nn.Linear(1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "418fcc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = input_proj(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c56a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graphs = torch.cat([ dgl[l](h, mask_M=torch.tensor(endpoint_adj[0])).unsqueeze(1) for l in range(3) ], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e1b1544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 1212, 1212])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_graphs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e65dfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1212, 1212])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([_graphs, _graphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42545bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62d8c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "_red_edge, _up_edge, edge_index = corr_labels_from_batch(   batch_x, \n",
    "                                                            batch_y,\n",
    "                                                            scaler=SCALER,  \n",
    "                                                            A_mask=torch.tensor(endpoint_adj[0], dtype=torch.bool),                # (N, N) bool; 1 = physically allowed (i->j)\n",
    "                                                            lags=[1,3,5],                 # e.g., [1,2,3]\n",
    "                                                            phys_thresholds=(0.2, 0.5),  # (tau_lo, tau_hi) for info; we use tau_hi\n",
    "                                                            label_only=False,            # True => return only significance labels (bool)\n",
    "                                                            device='cuda:0'                # where to compute\n",
    "                                                        )\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c279d891",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corr_speed_posneg_from_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _pos_edge, _neg_edge, edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mcorr_speed_posneg_from_batch\u001b[49m(\n\u001b[1;32m      2\u001b[0m                         batch_x,\n\u001b[1;32m      3\u001b[0m                         batch_y,\n\u001b[1;32m      4\u001b[0m                         scaler\u001b[38;5;241m=\u001b[39mSCALER,                              \u001b[38;5;66;03m# has .inverse_transform(tensor) -> raw\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                         A_mask\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(endpoint_adj[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool),              \u001b[38;5;66;03m# (N, N) bool; 1 = physically allowed (i->j)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                         lags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m],                 \u001b[38;5;66;03m# positive lags, e.g. [1,2,3]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                         tau_hi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,                 \u001b[38;5;66;03m# significance threshold for |rho| (if label_only)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                         label_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,            \u001b[38;5;66;03m# True → return boolean significance labels only\u001b[39;00m\n\u001b[1;32m      9\u001b[0m                         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m                     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corr_speed_posneg_from_batch' is not defined"
     ]
    }
   ],
   "source": [
    "_pos_edge, _neg_edge, edge_index = corr_speed_posneg_from_batch(\n",
    "                        batch_x,\n",
    "                        batch_y,\n",
    "                        scaler=SCALER,                              # has .inverse_transform(tensor) -> raw\n",
    "                        A_mask=torch.tensor(endpoint_adj[0], dtype=torch.bool),              # (N, N) bool; 1 = physically allowed (i->j)\n",
    "                        lags=[1,3,5],                 # positive lags, e.g. [1,2,3]\n",
    "                        tau_hi=0.5,                 # significance threshold for |rho| (if label_only)\n",
    "                        label_only=True,            # True → return boolean significance labels only\n",
    "                        device=\"cuda:0\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1a5a58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(60072, device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pos_edge.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "540fb206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50876, device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_neg_edge.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bcd90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J = torch.tensor(endpoint_adj[0]).nonzero(as_tuple=True)          # (E,)\n",
    "edge_index = torch.stack([I, J], dim=0)       # (2, E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a2c191c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    1,  ..., 1211, 1211, 1211],\n",
       "        [   1,  443,    0,  ...,  154,  155,  161]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0aea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_sparse_coo(logits_edges, edge_index, N):\n",
    "    B,L,E = logits_edges.shape\n",
    "    device = logits_edges.device\n",
    "    I,J = edge_index\n",
    "    b = torch.arange(B, device=device).view(B,1,1).expand(B,L,E).reshape(-1)\n",
    "    l = torch.arange(L, device=device).view(1,L,1).expand(B,L,E).reshape(-1)\n",
    "    i = I.view(1,1,E).expand(B,L,E).reshape(-1)\n",
    "    j = J.view(1,1,E).expand(B,L,E).reshape(-1)\n",
    "    idx = torch.stack([b,l,i,j], dim=0)\n",
    "    vals = logits_edges.reshape(-1)\n",
    "    return torch.sparse_coo_tensor(idx, vals, size=(B,L,N,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02fdd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectedLowRankEdgeScorer(nn.Module):\n",
    "    \"\"\"\n",
    "    (B,T,N,C) -> (B, L, E) logits on the provided edges.\n",
    "      - Directed: separate source/destination node scorers\n",
    "      - Low-rank: rank r\n",
    "      - Per-lag mixing: either diagonal (fast) or full bilinear (r x r)\n",
    "\n",
    "    Args:\n",
    "      in_dim:    node feature dim C (after your temporal projection)\n",
    "      hidden:    hidden size in node MLPs\n",
    "      rank_r:    low rank (>=1)\n",
    "      L:         number of lags to predict\n",
    "      pooling:   'last' or 'mean' over time dimension T\n",
    "      mix:       'diag' (default, efficient) or 'full' (r x r per lag)\n",
    "      nonneg:    if True, clamp embeddings >= 0 (optional)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden: int, rank_r: int, L: int,\n",
    "                 pooling: str = \"last\", mix: str = \"diag\", nonneg: bool = False):\n",
    "        super().__init__()\n",
    "        assert pooling in (\"last\", \"mean\")\n",
    "        assert mix in (\"diag\", \"full\")\n",
    "        self.pooling, self.mix, self.L, self.r = pooling, mix, L, rank_r\n",
    "        self.nonneg = nonneg\n",
    "\n",
    "        # Directed node scorers → a (source), b (dest)\n",
    "        self.src_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, rank_r)  # (B,N,r)\n",
    "        )\n",
    "        self.dst_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, rank_r)  # (B,N,r)\n",
    "        )\n",
    "\n",
    "        if mix == \"diag\":\n",
    "            # per-lag diagonal mixing γ_{ℓ,k}\n",
    "            self.gamma = nn.Parameter(torch.zeros(L, rank_r)) \n",
    "        else:\n",
    "            # per-lag full bilinear W_{ℓ} ∈ R^{r×r}\n",
    "            self.W = nn.Parameter(torch.zeros(L, rank_r, rank_r))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Kaiming on last layers; small bias to break symmetry\n",
    "        for lin in (self.src_mlp[-1], self.dst_mlp[-1]):\n",
    "            nn.init.kaiming_uniform_(lin.weight, a=0.1)\n",
    "            nn.init.uniform_(lin.bias, -0.01, 0.01)\n",
    "        if self.mix == \"diag\":\n",
    "            nn.init.uniform_(self.gamma, 0.01, 0.05)  # diag case\n",
    "        else:\n",
    "            nn.init.uniform_(self.W, -0.05, 0.05)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        X:          (B, T, N, C)\n",
    "        edge_index: (2, E) long (same device as X)\n",
    "        Returns:\n",
    "          logits_edges: (B, L, E)  — BCEWithLogits-ready\n",
    "        \"\"\"\n",
    "        device = X.device\n",
    "        B, T, N, C = X.shape\n",
    "        I, J = edge_index.to(device)  # (E,)\n",
    "\n",
    "        # Pool in time\n",
    "        H = X[:, -1] if self.pooling == \"last\" else X.mean(dim=1)  # (B,N,C)\n",
    "\n",
    "        # Node embeddings\n",
    "        a = self.src_mlp(H)   # (B,N,r)\n",
    "        b = self.dst_mlp(H)   # (B,N,r)\n",
    "        print (a.shape, b.shape)\n",
    "        if self.nonneg:\n",
    "            a, b = F.relu(a), F.relu(b)\n",
    "\n",
    "        # Gather only needed edges\n",
    "        # a_i: (B,E,r), b_j: (B,E,r)\n",
    "        a_i = a.index_select(dim=1, index=I)  # source\n",
    "        b_j = b.index_select(dim=1, index=J)  # dest\n",
    "\n",
    "        print (a_i.shape, b_j.shape)\n",
    "\n",
    "        if self.mix == \"diag\":\n",
    "            # (B,E,r) * (L,r) -> (B,L,E) via einsum: (be r)·(l r) over r\n",
    "            logits = torch.einsum(\"ber,lr,ber->ble\", a_i, self.gamma, b_j)\n",
    "        else:\n",
    "            # full bilinear: (a_i W_l)·b_j for each lag l\n",
    "            # a_i: (B,E,r), W: (L,r,r) → tmp: (B,E,L,r)\n",
    "            tmp = torch.einsum(\"ber,lrs->bels\", a_i, self.W)\n",
    "            logits = torch.einsum(\"bels,ber->ble\", tmp, b_j)\n",
    "\n",
    "        return logits  # (B, L, E) logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba30f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl = DirectedLowRankEdgeScorer(in_dim=40, hidden=64, rank_r=1, L=3,\n",
    "                 pooling=\"last\", mix=\"diag\", nonneg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "42fcb822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1212, 1]) torch.Size([32, 1212, 1])\n",
      "torch.Size([32, 6186, 1]) torch.Size([32, 6186, 1])\n"
     ]
    }
   ],
   "source": [
    "logits = dgl(h, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "85fa90a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0016, -0.0016, -0.0015,  ..., -0.0017, -0.0016, -0.0017],\n",
       "         [-0.0052, -0.0052, -0.0049,  ..., -0.0053, -0.0052, -0.0054],\n",
       "         [-0.0025, -0.0025, -0.0024,  ..., -0.0026, -0.0026, -0.0027]],\n",
       "\n",
       "        [[-0.0016, -0.0016, -0.0016,  ..., -0.0017, -0.0017, -0.0017],\n",
       "         [-0.0051, -0.0051, -0.0050,  ..., -0.0055, -0.0056, -0.0055],\n",
       "         [-0.0025, -0.0025, -0.0024,  ..., -0.0027, -0.0027, -0.0027]],\n",
       "\n",
       "        [[-0.0016, -0.0016, -0.0016,  ..., -0.0017, -0.0015, -0.0016],\n",
       "         [-0.0050, -0.0052, -0.0051,  ..., -0.0053, -0.0047, -0.0052],\n",
       "         [-0.0025, -0.0026, -0.0025,  ..., -0.0026, -0.0023, -0.0026]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0016, -0.0017, -0.0015,  ..., -0.0016, -0.0015, -0.0017],\n",
       "         [-0.0052, -0.0054, -0.0049,  ..., -0.0051, -0.0049, -0.0053],\n",
       "         [-0.0025, -0.0026, -0.0024,  ..., -0.0025, -0.0024, -0.0026]],\n",
       "\n",
       "        [[-0.0016, -0.0016, -0.0015,  ..., -0.0016, -0.0015, -0.0016],\n",
       "         [-0.0052, -0.0051, -0.0049,  ..., -0.0050, -0.0049, -0.0051],\n",
       "         [-0.0025, -0.0025, -0.0024,  ..., -0.0025, -0.0024, -0.0025]],\n",
       "\n",
       "        [[-0.0016, -0.0016, -0.0016,  ..., -0.0017, -0.0015, -0.0017],\n",
       "         [-0.0051, -0.0051, -0.0050,  ..., -0.0053, -0.0049, -0.0054],\n",
       "         [-0.0025, -0.0025, -0.0025,  ..., -0.0026, -0.0024, -0.0027]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4057268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_edges = torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d88a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = edges_to_sparse_coo(pred_edges, edge_index, N=h.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0272e8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4996, 0.0000, 0.4996,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4988, 0.0000, 0.4987,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4994, 0.0000, 0.4994,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4996, 0.0000, 0.4996,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4988, 0.0000, 0.4987,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4994, 0.0000, 0.4994,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4996, 0.0000, 0.4996,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4988, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4987, 0.0000, 0.4987,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4994, 0.0000, 0.4994,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4996, 0.0000, 0.4996,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4988, 0.0000, 0.4987,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4988, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4994, 0.0000, 0.4994,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4996, 0.0000, 0.4996,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4988, 0.0000, 0.4988,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4994, 0.0000, 0.4994,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4996, 0.0000, 0.4996,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4996, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4988, 0.0000, 0.4988,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4987, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4994, 0.0000, 0.4994,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4994, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "       grad_fn=<ToDenseBackward0>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7ba56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f430b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85b7c6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2847, 0.0000, 0.1803,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.2983, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1863],\n",
       "        [0.1787, 0.5536, 0.5702,  ..., 0.0000, 0.9402, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_red_edge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2847e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdcc2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_red_edge, sig_up_edge, edge_index = corr_labels_from_batch(   batch_x, \n",
    "                                                            batch_y,\n",
    "                                                            scaler=SCALER,  \n",
    "                                                            A_mask=torch.tensor(endpoint_adj[0], dtype=torch.bool),                # (N, N) bool; 1 = physically allowed (i->j)\n",
    "                                                            lags=[1,3,5],                 # e.g., [1,2,3]\n",
    "                                                            phys_thresholds=(0.2, 0.5),  # (tau_lo, tau_hi) for info; we use tau_hi\n",
    "                                                            label_only=True,            # True => return only significance labels (bool)\n",
    "                                                            device='cuda:0'                # where to compute\n",
    "                                                        )\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dddeb3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ True, False, False,  ..., False, False, False],\n",
       "          [ True, False,  True,  ..., False, False, False],\n",
       "          [False,  True, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False,  True, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False,  True, False],\n",
       "          [ True, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False,  True]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [ True, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False,  True,  ..., False, False, False],\n",
       "          [False, False, False,  ...,  True,  True, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False,  True,  ..., False, False, False],\n",
       "          [False,  True, False,  ..., False,  True, False],\n",
       "          [False, False, False,  ..., False, False, False]]], device='cuda:0'),\n",
       " tensor([[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False,  True,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False,  True],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False,  True,  ..., False, False, False],\n",
       "          [False,  True, False,  ...,  True, False, False]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[False, False, False,  ..., False, False,  True],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False,  True, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False,  True],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False,  True, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False,  True],\n",
       "          [False, False, False,  ..., False, False, False]]], device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_red_edge, sig_up_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772aec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b4a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04fe2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_generator = compute_ccf_two_channels_edges(trainset_loader, \n",
    "                                               lags=[1,3,5], \n",
    "                                               A_mask=torch.tensor(endpoint_adj[0], dtype=torch.bool), \n",
    "                                               scaler=SCALER, \n",
    "                                               device='cuda:0',\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4719e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1970/1970 [00:16<00:00, 118.88it/s]\n"
     ]
    }
   ],
   "source": [
    "all_red, all_up = [], []\n",
    "all_sig_red, all_sig_up = [], []\n",
    "all_band_red, all_band_up = [], []\n",
    "edge_index = None\n",
    "\n",
    "gen = compute_ccf_two_channels_edges(\n",
    "    trainset_loader,\n",
    "    lags=[1,3,5],\n",
    "    scaler=SCALER,\n",
    "    A_mask=torch.tensor(endpoint_adj[0], dtype=torch.bool),             # (N,N) binary adjacency\n",
    "    phys_thresholds=(0.2, 0.5),\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "for out in gen:\n",
    "    # Each batch produces (B,L,E) arrays\n",
    "    all_red.append(out[\"rho_red_edge\"])\n",
    "    all_up.append(out[\"rho_up_edge\"])\n",
    "    all_sig_red.append(out[\"sig_red_edge\"])\n",
    "    all_sig_up.append(out[\"sig_up_edge\"])\n",
    "    all_band_red.append(out[\"band_red_edge\"])\n",
    "    all_band_up.append(out[\"band_up_edge\"])\n",
    "    if edge_index is None:  # save once\n",
    "        edge_index = out[\"edge_index\"]\n",
    "\n",
    "# Concatenate along batch dimension\n",
    "rho_red_full  = torch.cat(all_red, dim=0)       # (Total_B, L, E)\n",
    "rho_up_full   = torch.cat(all_up, dim=0)\n",
    "sig_red_full  = torch.cat(all_sig_red, dim=0)\n",
    "sig_up_full   = torch.cat(all_sig_up, dim=0)\n",
    "band_red_full = torch.cat(all_band_red, dim=0)\n",
    "band_up_full  = torch.cat(all_band_up, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5315cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with PyTorch or NumPy\n",
    "torch.save({\n",
    "    \"rho_red\": rho_red_full,\n",
    "    \"rho_up\": rho_up_full,\n",
    "    \"sig_red\": sig_red_full,\n",
    "    \"sig_up\": sig_up_full,\n",
    "    \"band_red\": band_red_full,\n",
    "    \"band_up\": band_up_full,\n",
    "    \"edge_index\": edge_index,   # (2,E)\n",
    "    \"lags\": [1,3,5]\n",
    "}, \"../data/Inrix-Manhattan/ccf_edge_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b4c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402a7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087e273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1819862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rho_red_edge', 'rho_up_edge', 'sig_red_edge', 'sig_up_edge', 'band_red_edge', 'band_up_edge', 'edge_index'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3ea8d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212, 1212)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_adj[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee3aa183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 6186])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['sig_red_edge'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfafe718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6186])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['edge_index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6c5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03d155c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m all_rho_red, all_rho_up \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      2\u001b[0m ccf \u001b[38;5;241m=\u001b[39m compute_batchwise_ccf_two_channels_from_loader(trainset_loader, lags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m], scaler\u001b[38;5;241m=\u001b[39mSCALER, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrho_red\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_up\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mccf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_rho_red\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrho_red\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_rho_up\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrho_up\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.12/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 177\u001b[0m, in \u001b[0;36mcompute_batchwise_ccf_two_channels_from_loader\u001b[0;34m(trainset_loader, lags, scaler, device, A_mask, phys_thresholds, sparse)\u001b[0m\n\u001b[1;32m    175\u001b[0m rho_up   \u001b[38;5;241m=\u001b[39m _maybe_to_sparse(rho_up,   sparse)\n\u001b[1;32m    176\u001b[0m sig_up   \u001b[38;5;241m=\u001b[39m _maybe_to_sparse(sig_up,   sparse)\n\u001b[0;32m--> 177\u001b[0m band_up  \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_to_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband_up\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (sig_red, band_red,\n\u001b[1;32m    180\u001b[0m        sig_up,  band_up)\n",
      "Cell \u001b[0;32mIn[9], line 86\u001b[0m, in \u001b[0;36m_maybe_to_sparse\u001b[0;34m(x, sparse)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB. GPU "
     ]
    }
   ],
   "source": [
    "all_rho_red, all_rho_up = [], []\n",
    "ccf = compute_batchwise_ccf_two_channels_from_loader(trainset_loader, lags=[1,3,5], scaler=SCALER, device='cuda:0')\n",
    "\n",
    "for rho_red, rho_up in ccf:\n",
    "    all_rho_red.append(rho_red.cpu())\n",
    "    all_rho_up.append(rho_up.cpu())\n",
    "    break\n",
    "\n",
    "rho_red_full = torch.cat(all_rho_red, dim=0)  # (Total_B, L, N, N)\n",
    "rho_up_full  = torch.cat(all_rho_up, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d14c9979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2028, -0.1072, -0.2066,  ..., -0.2484,  0.0000, -0.2077],\n",
       "        [ 0.1201,  0.2713, -0.1708,  ..., -0.2054,  0.0000, -0.0337],\n",
       "        [-0.2066, -0.1708, -0.1235,  ..., -0.1485,  0.0000, -0.1651],\n",
       "        ...,\n",
       "        [ 0.7324, -0.1708,  1.1111,  ..., -0.1485,  0.0000, -0.1651],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2066, -0.1708, -0.1235,  ..., -0.1485,  0.0000, -0.1651]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_red_full[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9842d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = next(iter(trainset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ab5e8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  4.,  4.,  8.,  6., 10., 10.,  6.,  6.,  4.,  4.,  6.,\n",
       "        10.,  8.,  7.,  4.,  4.,  2.,  0.,  2.,  1.,  5.,  6.,  3.,  2.,\n",
       "         3.,  2.,  2.,  2.,  2.,  1.,  5.,  7.,  2.,  7.,  6.,  3.,  7.,\n",
       "         7., 15.,  5., 12.,  6., 21., 18., 11., 15., 10., 18.,  6.,  6.,\n",
       "         4.,  2.,  7.,  6.,  6.,  2.,  3.,  5.,  7.,  0.,  0.,  0., 12.,\n",
       "         1.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([  0.        ,   1.01010101,   2.02020202,   3.03030303,\n",
       "          4.04040404,   5.05050505,   6.06060606,   7.07070707,\n",
       "          8.08080808,   9.09090909,  10.1010101 ,  11.11111111,\n",
       "         12.12121212,  13.13131313,  14.14141414,  15.15151515,\n",
       "         16.16161616,  17.17171717,  18.18181818,  19.19191919,\n",
       "         20.2020202 ,  21.21212121,  22.22222222,  23.23232323,\n",
       "         24.24242424,  25.25252525,  26.26262626,  27.27272727,\n",
       "         28.28282828,  29.29292929,  30.3030303 ,  31.31313131,\n",
       "         32.32323232,  33.33333333,  34.34343434,  35.35353535,\n",
       "         36.36363636,  37.37373737,  38.38383838,  39.39393939,\n",
       "         40.4040404 ,  41.41414141,  42.42424242,  43.43434343,\n",
       "         44.44444444,  45.45454545,  46.46464646,  47.47474747,\n",
       "         48.48484848,  49.49494949,  50.50505051,  51.51515152,\n",
       "         52.52525253,  53.53535354,  54.54545455,  55.55555556,\n",
       "         56.56565657,  57.57575758,  58.58585859,  59.5959596 ,\n",
       "         60.60606061,  61.61616162,  62.62626263,  63.63636364,\n",
       "         64.64646465,  65.65656566,  66.66666667,  67.67676768,\n",
       "         68.68686869,  69.6969697 ,  70.70707071,  71.71717172,\n",
       "         72.72727273,  73.73737374,  74.74747475,  75.75757576,\n",
       "         76.76767677,  77.77777778,  78.78787879,  79.7979798 ,\n",
       "         80.80808081,  81.81818182,  82.82828283,  83.83838384,\n",
       "         84.84848485,  85.85858586,  86.86868687,  87.87878788,\n",
       "         88.88888889,  89.8989899 ,  90.90909091,  91.91919192,\n",
       "         92.92929293,  93.93939394,  94.94949495,  95.95959596,\n",
       "         96.96969697,  97.97979798,  98.98989899, 100.        ]),\n",
       " <BarContainer object of 99 artists>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot raw speed distribution '''\n",
    "link_idx = 1045\n",
    "link_speed = SCALER.inverse_transform(batch_x[:,:, link_idx, :])\n",
    "plt.hist(torch.flatten(link_speed), np.linspace(0, 100, 100), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5860d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b30ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get a sample road time-series '''\n",
    "sample_x_speed = SCALER.inverse_transform(batch_x[0,:,545, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87e8e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y_speed = batch_y[0,:,545, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "597ac675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000],\n",
       "        [15.0000],\n",
       "        [13.0000],\n",
       "        [12.0000],\n",
       "        [ 7.0000],\n",
       "        [ 8.0000],\n",
       "        [11.0000],\n",
       "        [11.0000],\n",
       "        [11.0000],\n",
       "        [13.0000],\n",
       "        [11.0000],\n",
       "        [12.0000]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9730dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_y_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536be2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b870aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_row_softmax(logits: torch.Tensor,\n",
    "                       mask: torch.Tensor,\n",
    "                       temperature: float = 1.0,\n",
    "                       fallback_self_loop: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Perform row-wise softmax only over entries where mask==1; others get prob 0.\n",
    "    If a row has no allowed entries and fallback_self_loop=True, we set the diagonal\n",
    "    mask to 1 for that row before softmax (so it becomes a self-loop).\n",
    "    Shapes: logits, mask -> (B,N,N) or (1,N,N) for mask (will broadcast to B).\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        # standard row-softmax over all columns\n",
    "        return F.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "    # Broadcast mask to (B,N,N)\n",
    "    m = mask.bool()\n",
    "    if m.dim() == 3 and logits.dim() == 3 and m.size(0) == 1:\n",
    "        m = m.expand(logits.size(0), -1, -1)\n",
    "\n",
    "    B, N, _ = logits.shape\n",
    "    # Optionally ensure at least one allowed entry per row (to avoid all -inf → NaN)\n",
    "    if fallback_self_loop:\n",
    "        row_has_any = m.any(dim=-1)  # (B,N)\n",
    "        if (~row_has_any).any():\n",
    "            eye = torch.eye(N, device=logits.device, dtype=m.dtype).bool().unsqueeze(0)\n",
    "            m = torch.where(~row_has_any.unsqueeze(-1) & eye, True, m)\n",
    "\n",
    "    # Set disallowed positions to -inf so softmax gives ~0 there\n",
    "    neg_inf = torch.finfo(logits.dtype).min\n",
    "    masked_logits = torch.where(m, logits / temperature, neg_inf)\n",
    "\n",
    "    # Numerically stable softmax: subtract row-max over allowed entries\n",
    "    row_max = masked_logits.max(dim=-1, keepdim=True).values  # (B,N,1)\n",
    "    exps = torch.exp(masked_logits - row_max) * m  # zero where disallowed\n",
    "    denom = exps.sum(dim=-1, keepdim=True).clamp_min(1e-12)\n",
    "    probs = exps / denom\n",
    "    return probs  # (B,N,N), rows sum to 1 over allowed entries only\n",
    "\n",
    "def masked_sigmoid(logits: torch.Tensor,\n",
    "                   mask: torch.Tensor,\n",
    "                   temperature: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Independent sigmoid activation with masking.\n",
    "    Shapes: logits, mask -> (B,N,N)\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(logits / temperature)\n",
    "    if mask is not None:\n",
    "        probs = probs * mask\n",
    "    return probs\n",
    "\n",
    "\n",
    "class TemporalNodeEncoder(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int = 64, out_dim: int = 64, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=in_dim, hidden_size=hidden,\n",
    "                          batch_first=True, bidirectional=bidirectional)\n",
    "        self.proj = nn.Linear(hidden*(2 if bidirectional else 1), out_dim)\n",
    "\n",
    "    def forward(self, x_BTNC: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, N, C = x_BTNC.shape\n",
    "        x = x_BTNC.permute(0, 2, 1, 3).reshape(B*N, T, C)   # (B*N,T,C)\n",
    "        h, _ = self.gru(x)\n",
    "        h = self.proj(h[:, -1])                             # (B*N,H)\n",
    "        return h.view(B, N, -1)                             # (B,N,H)\n",
    "\n",
    "\n",
    "class EdgeScorer(nn.Module):\n",
    "    def __init__(self, node_dim: int, edge_feat_dim: int = 0, hidden: int = 128):\n",
    "        super().__init__()\n",
    "        in_d = 4*node_dim + edge_feat_dim      # [hi, hj, hi-hj, hi*hj, (+ e_ij)]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_d, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, H_BNH: torch.Tensor, Efeat_BNNE: torch.Tensor | None = None) -> torch.Tensor:\n",
    "        B, N, H = H_BNH.shape\n",
    "        hi = H_BNH[:, :, None, :].expand(B, N, N, H)\n",
    "        hj = H_BNH[:, None, :, :].expand(B, N, N, H)\n",
    "        feats = [hi, hj, hi - hj, hi * hj]\n",
    "        if Efeat_BNNE is not None:\n",
    "            feats.append(Efeat_BNNE)\n",
    "        Z = torch.cat(feats, dim=-1)\n",
    "        return self.mlp(Z).squeeze(-1)  # (B,N,N)\n",
    "\n",
    "\n",
    "class PropagationGraphLearner(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns a soft, directed propagation graph G (B,N,N) with masked row-softmax.\n",
    "    Self-loops are allowed if the mask diagonal is 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, node_dim: int = 64, edge_hidden: int = 128,\n",
    "                 scorer_edge_feat_dim: int = 0, temperature: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = TemporalNodeEncoder(in_dim, hidden=node_dim, out_dim=node_dim)\n",
    "        self.scorer  = EdgeScorer(node_dim, edge_feat_dim=scorer_edge_feat_dim, hidden=edge_hidden)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, x_BTNC: torch.Tensor,\n",
    "                mask_M: torch.Tensor,                  # (1 or B, N, N) with 1=allowed (neighbors)\n",
    "                edge_feats: torch.Tensor | None = None,\n",
    "                fallback_self_loop: bool = True):\n",
    "        H = self.encoder(x_BTNC)                        # (B,N,H)\n",
    "        logits = self.scorer(H, edge_feats)             # (B,N,N), includes self logits\n",
    "        soft = masked_row_softmax(logits, mask_M, self.temperature, fallback_self_loop)\n",
    "        return soft  # (B,N,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8548346",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, N, C = 4, 12, 1212, 8\n",
    "x = torch.randn(B, T, N, C)\n",
    "\n",
    "learner = PropagationGraphLearner(\n",
    "    in_dim=C,\n",
    "    node_dim=64,\n",
    "    edge_hidden=128,\n",
    "    scorer_edge_feat_dim=0,     # set to E.shape[-1] if you pass edge features\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6fd461ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_P = learner(x, mask_M=torch.tensor(endpoint_adj[0]), edge_feats=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b10efdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.5018, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4930, 0.0000, 0.5070,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3319, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.4966, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5003, 0.0000, 0.4997,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3311, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.5053, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4964, 0.0000, 0.5036,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3318, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.4988, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5112, 0.0000, 0.4888,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3350, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ef5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611abbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7dfe8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3af2ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_tree_marginals(scores: torch.Tensor, mask_G: torch.Tensor, tau: float = 0.1):\n",
    "    \"\"\"\n",
    "    Differentiable edge marginals for the random spanning tree distribution\n",
    "    restricted to G, using Kirchhoff / Matrix-Tree theorem.\n",
    "\n",
    "    scores : (N,N) torch, symmetric logits for edges\n",
    "    mask_G : (N,N) torch/bool, 1 where edge allowed in G\n",
    "    tau    : temperature; smaller -> sharper (closer to hard MST), but gradients get steeper\n",
    "\n",
    "    Returns:\n",
    "      P : (N,N) torch, symmetric in [0,1], expected incidence of each undirected edge.\n",
    "    \"\"\"\n",
    "    N = scores.shape[0]\n",
    "    sym_scores = 0.5 * (scores + scores.T)\n",
    "    # Allowed, positive weights (zero elsewhere)\n",
    "    W = torch.where(mask_G.bool(), torch.exp(sym_scores / tau), torch.zeros_like(sym_scores))\n",
    "    W = W - torch.diag(torch.diag(W))  # zero diagonal\n",
    "    W = 0.5 * (W + W.T)\n",
    "\n",
    "    # Laplacian\n",
    "    d = W.sum(dim=1)\n",
    "    L = torch.diag(d) - W\n",
    "\n",
    "    # Pseudoinverse (add tiny jitter for stability on GPU)\n",
    "    # NOTE: For large N, use a Cholesky-based solver on the (N-1)x(N-1) cofactor instead.\n",
    "    eps = 1e-6\n",
    "    L_ = L + eps * torch.eye(N, device=L.device, dtype=L.dtype)\n",
    "    L_pinv = torch.linalg.pinv(L_)\n",
    "\n",
    "    # Effective resistance matrix R_ij = L^+_ii + L^+_jj - 2 L^+_ij\n",
    "    diag = torch.diag(L_pinv).unsqueeze(0)  # shape 1xN\n",
    "    R = diag + diag.T - 2.0 * L_pinv\n",
    "\n",
    "    # Edge marginals\n",
    "    P = W * R\n",
    "    # Clean numerics/symmetry\n",
    "    P = 0.5 * (P + P.T)\n",
    "    P = torch.clamp(P, min=0.0, max=1.0)\n",
    "    P = P - torch.diag(torch.diag(P))\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b678ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f3ff0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.nn.Parameter(torch.randn(N, N) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36614cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = soft_tree_marginals(scores, mask_G=torch.tensor(endpoint_adj[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8443042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  14.,  18.,  46.,  68.,  82.,  68.,  72., 112.,  96., 114.,\n",
       "        134., 138., 132., 126., 112., 168., 124., 110., 104., 142., 150.,\n",
       "        132.,  82.,  94., 116., 116., 114., 106., 112., 108.,  90., 102.,\n",
       "         96.,  68., 102., 100.,  78.,  96., 104.,  82.,  78.,  82.,  68.,\n",
       "         64.,  62.,  70.,  64.,  56.,  82.,  52.,  48.,  68.,  54.,  72.,\n",
       "         50.,  46.,  44.,  30.,  26.,  38.,  28.,  42.,  28.,  48.,  28.,\n",
       "         26.,  22.,  26.,  30.,  20.,  32.,  28.,  34.,  16.,   8.,  16.,\n",
       "         20.,  22.,   6.,  12.,   6.,  10.,  10.,  24.,  16.,  18.,  22.,\n",
       "         18.,  12.,  10.,  20.,  14.,  26.,   8.,  18.,   4.,  26.,  16.,\n",
       "        222.]),\n",
       " array([0.02739118, 0.03711727, 0.04684336, 0.05656945, 0.06629553,\n",
       "        0.07602162, 0.08574771, 0.0954738 , 0.10519989, 0.11492597,\n",
       "        0.12465207, 0.13437815, 0.14410424, 0.15383032, 0.16355641,\n",
       "        0.1732825 , 0.1830086 , 0.19273467, 0.20246077, 0.21218686,\n",
       "        0.22191295, 0.23163903, 0.24136512, 0.25109121, 0.26081729,\n",
       "        0.2705434 , 0.28026947, 0.28999555, 0.29972166, 0.30944774,\n",
       "        0.31917381, 0.32889992, 0.338626  , 0.3483521 , 0.35807818,\n",
       "        0.36780426, 0.37753037, 0.38725644, 0.39698252, 0.40670863,\n",
       "        0.41643471, 0.42616078, 0.43588689, 0.44561297, 0.45533907,\n",
       "        0.46506515, 0.47479123, 0.48451734, 0.49424341, 0.50396949,\n",
       "        0.5136956 , 0.5234217 , 0.53314775, 0.54287386, 0.55259997,\n",
       "        0.56232601, 0.57205212, 0.58177823, 0.59150428, 0.60123038,\n",
       "        0.61095649, 0.62068254, 0.63040864, 0.64013475, 0.6498608 ,\n",
       "        0.65958691, 0.66931301, 0.67903906, 0.68876517, 0.69849128,\n",
       "        0.70821738, 0.71794343, 0.72766954, 0.73739564, 0.74712169,\n",
       "        0.7568478 , 0.76657391, 0.77629995, 0.78602606, 0.79575217,\n",
       "        0.80547822, 0.81520432, 0.82493043, 0.83465648, 0.84438258,\n",
       "        0.85410869, 0.86383474, 0.87356085, 0.88328695, 0.893013  ,\n",
       "        0.90273911, 0.91246521, 0.92219132, 0.93191737, 0.94164348,\n",
       "        0.95136958, 0.96109563, 0.97082174, 0.98054785, 0.99027389,\n",
       "        1.        ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mst[[endpoint_adj[0]>0]].detach().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ce920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc3253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2f1c10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc1ef50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_adj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2371eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = endpoint_adj[0] - adj_mx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d77c696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4321, 0, 1865)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(diff[diff>0]), np.sum(diff[diff<0]), np.sum(adj_mx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be57caea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09480062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84af8a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dachuan/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- set loss, optimizer, scheduler ---------------------- #\n",
    "from functools import partial\n",
    "\n",
    "model = partial(STGformer)\n",
    "model = model(**cfg[\"model_args\"], supports=supports)\n",
    "model = model.to(DEVICE)\n",
    "criterion = MaskedMAELoss()  # MaskedHuberLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=cfg[\"lr\"],\n",
    "    weight_decay=cfg.get(\"weight_decay\", 0),\n",
    "    eps=cfg.get(\"eps\", 1e-8),\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=cfg[\"milestones\"],\n",
    "    gamma=cfg.get(\"lr_decay_rate\"),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ff3adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the latest model: ../saved_models/STGformer-INRIX_MANHATTAN-2025-09-29-09-19-43.pt\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- set model saving path -------------------------- #\n",
    "save_path = f\"../saved_models/\"\n",
    "\n",
    "model_files = glob.glob(os.path.join(save_path, f\"{model_name}-{dataset}-*.pt\"))\n",
    "if not model_files:\n",
    "    raise ValueError(\"No saved model found for testing.\")\n",
    "latest_model = max(model_files, key=os.path.getctime)\n",
    "loaded_model = latest_model if path_to_Weight is None else path_to_Weight\n",
    "print_log(f\"Loading the latest model: {loaded_model}\", log=log)\n",
    "model.load_state_dict(torch.load(loaded_model))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24079a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- STGformer ---------\n",
      "{\n",
      "    \"num_nodes\": 1212,\n",
      "    \"in_steps\": 12,\n",
      "    \"out_steps\": 1,\n",
      "    \"train_size\": 0.6,\n",
      "    \"val_size\": 0.2,\n",
      "    \"time_of_day\": false,\n",
      "    \"day_of_week\": false,\n",
      "    \"lr\": 0.001,\n",
      "    \"weight_decay\": 0.0015,\n",
      "    \"milestones\": [\n",
      "        60,\n",
      "        100,\n",
      "        140,\n",
      "        180\n",
      "    ],\n",
      "    \"lr_decay_rate\": 0.1,\n",
      "    \"batch_size\": 32,\n",
      "    \"max_epochs\": 300,\n",
      "    \"early_stop\": 30,\n",
      "    \"use_cl\": false,\n",
      "    \"cl_step_size\": 2500,\n",
      "    \"model_args\": {\n",
      "        \"num_nodes\": 1212,\n",
      "        \"in_steps\": 12,\n",
      "        \"out_steps\": 1,\n",
      "        \"steps_per_day\": 288,\n",
      "        \"input_dim\": 1,\n",
      "        \"output_dim\": 1,\n",
      "        \"input_embedding_dim\": 24,\n",
      "        \"tod_embedding_dim\": 0,\n",
      "        \"dow_embedding_dim\": 0,\n",
      "        \"adaptive_embedding_dim\": 12,\n",
      "        \"kernel_size\": [\n",
      "            1\n",
      "        ],\n",
      "        \"num_heads\": 4,\n",
      "        \"num_layers\": 6,\n",
      "        \"dropout\": 0.1,\n",
      "        \"dropout_a\": 0.35\n",
      "    }\n",
      "}\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "STGformer                                     [32, 1, 1212, 1]          174,528\n",
      "├─Linear: 1-1                                 [32, 12, 1212, 24]        48\n",
      "├─Dropout: 1-2                                [32, 12, 1212, 12]        --\n",
      "├─Conv2d: 1-3                                 [32, 36, 1212, 12]        1,332\n",
      "├─AvgPool2d: 1-4                              [1212, 1212, 12]          --\n",
      "├─ModuleList: 1-5                             --                        --\n",
      "│    └─SelfAttentionLayer: 2-1                [32, 12, 1212, 36]        --\n",
      "│    │    └─GraphPropagate: 3-1               [32, 12, 1212, 36]        --\n",
      "│    │    └─ModuleList: 3-4                   --                        (recursive)\n",
      "│    │    └─ModuleList: 3-5                   --                        (recursive)\n",
      "│    │    └─ModuleList: 3-4                   --                        (recursive)\n",
      "│    │    └─ModuleList: 3-5                   --                        (recursive)\n",
      "│    │    └─Dropout: 3-6                      [32, 12, 1212, 36]        --\n",
      "│    │    └─LayerNorm: 3-7                    [32, 12, 1212, 36]        72\n",
      "│    │    └─Mlp: 3-8                          [32, 12, 1212, 36]        5,292\n",
      "│    │    └─Dropout: 3-9                      [32, 12, 1212, 36]        --\n",
      "│    │    └─LayerNorm: 3-10                   [32, 12, 1212, 36]        72\n",
      "├─Linear: 1-6                                 [32, 1212, 36]            15,588\n",
      "├─ModuleList: 1-7                             --                        --\n",
      "│    └─Mlp: 2-2                               [32, 1212, 36]            --\n",
      "│    │    └─Linear: 3-11                      [32, 1212, 72]            2,664\n",
      "│    │    └─ReLU: 3-12                        [32, 1212, 72]            --\n",
      "│    │    └─Dropout: 3-13                     [32, 1212, 72]            --\n",
      "│    │    └─Identity: 3-14                    [32, 1212, 72]            --\n",
      "│    │    └─Linear: 3-15                      [32, 1212, 36]            2,628\n",
      "│    │    └─Dropout: 3-16                     [32, 1212, 36]            --\n",
      "│    └─Mlp: 2-3                               [32, 1212, 36]            --\n",
      "│    │    └─Linear: 3-17                      [32, 1212, 72]            2,664\n",
      "│    │    └─ReLU: 3-18                        [32, 1212, 72]            --\n",
      "│    │    └─Dropout: 3-19                     [32, 1212, 72]            --\n",
      "│    │    └─Identity: 3-20                    [32, 1212, 72]            --\n",
      "│    │    └─Linear: 3-21                      [32, 1212, 36]            2,628\n",
      "│    │    └─Dropout: 3-22                     [32, 1212, 36]            --\n",
      "│    └─Mlp: 2-4                               [32, 1212, 36]            --\n",
      "│    │    └─Linear: 3-23                      [32, 1212, 72]            2,664\n",
      "│    │    └─ReLU: 3-24                        [32, 1212, 72]            --\n",
      "│    │    └─Dropout: 3-25                     [32, 1212, 72]            --\n",
      "│    │    └─Identity: 3-26                    [32, 1212, 72]            --\n",
      "│    │    └─Linear: 3-27                      [32, 1212, 36]            2,628\n",
      "│    │    └─Dropout: 3-28                     [32, 1212, 36]            --\n",
      "│    └─Mlp: 2-5                               [32, 1212, 36]            --\n",
      "│    │    └─Linear: 3-29                      [32, 1212, 72]            2,664\n",
      "│    │    └─ReLU: 3-30                        [32, 1212, 72]            --\n",
      "│    │    └─Dropout: 3-31                     [32, 1212, 72]            --\n",
      "│    │    └─Identity: 3-32                    [32, 1212, 72]            --\n",
      "│    │    └─Linear: 3-33                      [32, 1212, 36]            2,628\n",
      "│    │    └─Dropout: 3-34                     [32, 1212, 36]            --\n",
      "│    └─Mlp: 2-6                               [32, 1212, 36]            --\n",
      "│    │    └─Linear: 3-35                      [32, 1212, 72]            2,664\n",
      "│    │    └─ReLU: 3-36                        [32, 1212, 72]            --\n",
      "│    │    └─Dropout: 3-37                     [32, 1212, 72]            --\n",
      "│    │    └─Identity: 3-38                    [32, 1212, 72]            --\n",
      "│    │    └─Linear: 3-39                      [32, 1212, 36]            2,628\n",
      "│    │    └─Dropout: 3-40                     [32, 1212, 36]            --\n",
      "│    └─Mlp: 2-7                               [32, 1212, 36]            --\n",
      "│    │    └─Linear: 3-41                      [32, 1212, 72]            2,664\n",
      "│    │    └─ReLU: 3-42                        [32, 1212, 72]            --\n",
      "│    │    └─Dropout: 3-43                     [32, 1212, 72]            --\n",
      "│    │    └─Identity: 3-44                    [32, 1212, 72]            --\n",
      "│    │    └─Linear: 3-45                      [32, 1212, 36]            2,628\n",
      "│    │    └─Dropout: 3-46                     [32, 1212, 36]            --\n",
      "├─Linear: 1-8                                 [32, 1212, 1]             37\n",
      "===============================================================================================\n",
      "Total params: 244,417\n",
      "Trainable params: 244,417\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 622.12\n",
      "===============================================================================================\n",
      "Input size (MB): 1.86\n",
      "Forward/backward pass size (MB): 2446.49\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 2448.64\n",
      "===============================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- print model structure -------------------------- #\n",
    "\n",
    "print_log(\"---------\", model_name, \"---------\", log=log)\n",
    "print_log(\n",
    "    json.dumps(cfg, ensure_ascii=False, indent=4, cls=CustomJSONEncoder), log=log\n",
    ")\n",
    "print_log(\n",
    "    summary(\n",
    "        model,\n",
    "        [\n",
    "            cfg[\"batch_size\"],\n",
    "            cfg[\"in_steps\"],\n",
    "            cfg[\"num_nodes\"],\n",
    "            next(iter(trainset_loader))[0].shape[-1],\n",
    "        ],\n",
    "        verbose=0,  # avoid print twice\n",
    "        device=DEVICE,\n",
    "    ),\n",
    "    log=log,\n",
    ")\n",
    "print_log(log=log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10997f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Test ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 656/656 [00:33<00:00, 19.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Steps RMSE = 5.18408, MAE = 2.50651, MAPE = 18.47258\n",
      "Step 1 RMSE = 5.18408, MAE = 2.50651, MAPE = 18.47258\n",
      "Inference time: 33.41 s\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- evaluate model performance --------------------------- #\n",
    "test_model(model, testset_loader, log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27718ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- inference graph --------------------------- #\n",
    "graph = inference_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7057535",
   "metadata": {},
   "source": [
    "### Inference wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "931097f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "@torch.no_grad()\n",
    "def average_U_instance(model, loader, steps=8):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    # 1) Find the noflayer instance actually used\n",
    "    wave = model.attn_layers_s[0].locals.wavelet_layer  # your noflayer instance\n",
    "\n",
    "    # 2) Keep originals\n",
    "    orig_attention = wave.attention\n",
    "\n",
    "    # 3) Tape + tapped attention\n",
    "    TAPE = {'Ulist': []}\n",
    "    def tapped_attention(self, x_BTNC, A_TNN):\n",
    "        U, P, A_BTNN = orig_attention(x_BTNC, A_TNN)  # call the real thing\n",
    "        TAPE['Ulist'].append(U.detach().cpu())\n",
    "        return U, P, A_BTNN\n",
    "\n",
    "    # 4) Monkey-patch the INSTANCE (bind with MethodType)\n",
    "    wave.attention = types.MethodType(tapped_attention, wave)\n",
    "\n",
    "    U_acc, n = None, 0\n",
    "    it = iter(loader)\n",
    "    try:\n",
    "        for _ in range(steps):\n",
    "            batch = next(it)\n",
    "            batch_x = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            _ = model(batch_x)  # this will now push U’s into TAPE\n",
    "\n",
    "            for U in TAPE['Ulist']:\n",
    "                Umean = U.mean(0).mean(0).numpy()  # (T,N,N) → (N,N)\n",
    "                U_acc = Umean if U_acc is None else U_acc + Umean\n",
    "                n += 1\n",
    "            TAPE['Ulist'].clear()\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    finally:\n",
    "        # 5) Restore original method no matter what\n",
    "        wave.attention = orig_attention\n",
    "\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"average_U_instance: never captured any U. \"\n",
    "                           \"Check that the forward actually calls wavelet_layer.attention.\")\n",
    "    return U_acc / n  # Ubar (N,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4171ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- inference wavelets --------------------------- #\n",
    "def get_coe_cheb(wave):\n",
    "    coe  = torch.sigmoid(wave.temp).detach().cpu().numpy()\n",
    "    cheb = torch.sigmoid(wave.cheb).detach().cpu().numpy()\n",
    "    if wave.alpha_ is not None:  # override if alpha_ is set\n",
    "        a1 = float(wave.alpha_)\n",
    "        a2 = float(wave.alpha_)\n",
    "    else:\n",
    "        a1 = float(coe[1])\n",
    "        a2 = float(coe[2])\n",
    "    return a1, a2, cheb\n",
    "\n",
    "def compute_betas(K, a1, a2, cheb, r0):\n",
    "    betas = []\n",
    "    r_s = float(r0)\n",
    "    for s in range(K):  # s=0..K-1 => k=s+1\n",
    "        w_s = 1.0 - (1.0 - a1) * r_s\n",
    "        beta = (1.0 - a2) * (a2 ** (K-1 - s)) * w_s\n",
    "        betas.append(beta)\n",
    "        if s < K-1 and len(cheb) > s:\n",
    "            r_s *= float(cheb[s])\n",
    "    return np.array(betas, dtype=float)  # shape (K,)\n",
    "\n",
    "def poly_operator(Ubar, betas, symmetrize=True):\n",
    "    U = 0.5*(Ubar+Ubar.T) if symmetrize else Ubar\n",
    "    N = U.shape[0]\n",
    "    M = np.zeros((N,N), dtype=float)\n",
    "    Uk = np.eye(N)\n",
    "    for k, beta_k in enumerate(betas, start=1):\n",
    "        Uk = Uk @ U\n",
    "        M += beta_k * Uk\n",
    "    return M\n",
    "\n",
    "def centered_poly_operator(Ubar, betas):\n",
    "    U = 0.5*(Ubar+Ubar.T)\n",
    "    # stationary distribution ~ principal eigenvector (normalize to sum 1)\n",
    "    vals, vecs = np.linalg.eigh(U)\n",
    "    v = vecs[:, -1]; pi = np.abs(v); pi = pi / pi.sum()\n",
    "    J = np.ones((U.shape[0],1)) @ pi[None,:]  # 1 * pi^T\n",
    "\n",
    "    M = np.zeros_like(U)\n",
    "    Uk = np.eye(U.shape[0])\n",
    "    for k, beta in enumerate(betas, start=1):\n",
    "        Uk = Uk @ U\n",
    "        M += beta * (Uk - J)          # <-- remove rank-1 limit each hop\n",
    "    return M\n",
    "\n",
    "def poly_operator_unsym(Ubar, betas):\n",
    "    M = np.zeros_like(Ubar)\n",
    "    Uk = np.eye(Ubar.shape[0])\n",
    "    for k, beta in enumerate(betas, start=1):\n",
    "        Uk = Uk @ Ubar\n",
    "        M += beta * Uk\n",
    "    return M\n",
    "\n",
    "def row_topk(U, k=8):\n",
    "    U2 = U.copy()\n",
    "    idx = np.argsort(U2, axis=1)[:, :-k]\n",
    "    U2[np.arange(U2.shape[0])[:,None], idx] = 0.0\n",
    "    # renormalize rows\n",
    "    rs = U2.sum(axis=1, keepdims=True); rs[rs==0]=1\n",
    "    return U2/rs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "233d3bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GraphPropagate' object has no attribute 'wavelet_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wave \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_layers_s\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwavelet_layer\u001b[49m\n\u001b[1;32m      2\u001b[0m a1, a2, cheb \u001b[38;5;241m=\u001b[39m get_coe_cheb(wave)\n\u001b[1;32m      3\u001b[0m betas \u001b[38;5;241m=\u001b[39m compute_betas(\u001b[38;5;241m1\u001b[39m, a1, a2, cheb, \u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.12/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphPropagate' object has no attribute 'wavelet_layer'"
     ]
    }
   ],
   "source": [
    "wave = model.attn_layers_s[0].locals.wavelet_layer\n",
    "a1, a2, cheb = get_coe_cheb(wave)\n",
    "betas = compute_betas(1, a1, a2, cheb, 0.5)\n",
    "Ubar = average_U_instance(model, trainset_loader, steps=8)\n",
    "Ubar_k = row_topk(Ubar, k=8)\n",
    "m_indices = poly_operator_unsym(Ubar_k, betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c887a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00030940594"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_indices.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e39eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.212e+03],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.212e+03],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.212e+03],\n",
       "        ...,\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.212e+03],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.212e+03],\n",
       "        [1.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.211e+03]]),\n",
       " array([-2.18278728e-11, -2.13913158e-11, -2.09547588e-11, -2.05182000e-11,\n",
       "        -2.00816429e-11, -1.96450859e-11, -1.92085289e-11, -1.87719701e-11,\n",
       "        -1.83354130e-11, -1.78988560e-11, -1.74622990e-11, -1.70257402e-11,\n",
       "        -1.65891832e-11, -1.61526261e-11, -1.57160691e-11, -1.52795103e-11,\n",
       "        -1.48429533e-11, -1.44063962e-11, -1.39698383e-11, -1.35332813e-11,\n",
       "        -1.30967234e-11, -1.26601663e-11, -1.22236084e-11, -1.17870514e-11,\n",
       "        -1.13504935e-11, -1.09139364e-11, -1.04773794e-11, -1.00408215e-11,\n",
       "        -9.60426443e-12, -9.16770652e-12, -8.73114948e-12, -8.29459158e-12,\n",
       "        -7.85803454e-12, -7.42147663e-12, -6.98491915e-12, -6.54836168e-12,\n",
       "        -6.11180421e-12, -5.67524673e-12, -5.23868969e-12, -4.80213222e-12,\n",
       "        -4.36557474e-12, -3.92901727e-12, -3.49245958e-12, -3.05590210e-12,\n",
       "        -2.61934485e-12, -2.18278737e-12, -1.74622979e-12, -1.30967242e-12,\n",
       "        -8.73114894e-13, -4.36557447e-13,  0.00000000e+00]),\n",
       " <a list of 1212 BarContainer objects>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(m_indices, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c54be917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003094059502473101"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_indices.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d562c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00030940592841943726"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_indices.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
